{"paragraphs":[{"text":"\n      def loadTim() = {\n        val props = scala.collection.mutable.Map[String, String]();\n        props += (\"driver\" -> \"com.mysql.jdbc.Driver\")\n        props += (\"url\" -> \"jdbc:mysql://172.16.2.114:3306/test?user=root&password=EMRroot1234\") //拉取维度数据源 做跨平台 跨数据源分析\n        props += (\"dbtable\" -> \"date_dim\") //默认一个rdd分区，可通过以下优化：\n        // //sql 是查询语句，此查询语句必须包含两处占位符?来作为分割数据库ResulSet的参数，例如：\"select title, author from books where ? < = id and id <= ?\"\n        // props+=(\"partitionColumn\" -> \"id\")//分区字段，须数字类型\n        // props+=(\"lowerBound\" -> \"0\")//分区下界\n        // props+=(\"upperBound\" -> \"100\")\n        // //owerBound, upperBound, numPartitions 分别为第一、第二占位符，partition的个数。例如，给出lowebound 1，upperbound 20， numpartitions 2，则查询分别为(1, 10)与(11, 20)\n        // props+=(\"numPartitions\" -> \"2\")//分区数\n        import scala.collection.JavaConverters._\n    \n        var jdbcDF = sqlContext.load(\"jdbc\", props.asJava) //加载数据\n        // jdbcDF.first\n        // jdbcDF.cache //OOM\n        // import org.apache.spark.storage.StorageLevel\n        // jdbcDF.persist(StorageLevel.MEMORY_AND_DISK_SER)\n    \n        jdbcDF.registerTempTable(\"date_dim\") //注册表\n        // sqlContext.cacheTable(\"customer_activity\")\n        sqlContext.cacheTable(\"date_dim\") //缓存表\n        //    sqlContext.sql(\"select * from date_dim limit 1\").show\n    \n        // props += (\"dbtable\" -> \"area_dim\")\n        // jdbcDF = sqlContext.load(\"jdbc\", props.asJava) //加载注册多表\n        // jdbcDF.registerTempTable(\"area_dim\")\n        // sqlContext.cacheTable(\"area_dim\") //缓存表\n        //    sqlContext.sql(\"select * from area_dim limit 1\").show;\n    \n        props += (\"dbtable\" -> \"time_dim\")\n        jdbcDF = sqlContext.load(\"jdbc\", props.asJava) //加载注册多表\n        jdbcDF.registerTempTable(\"time_dim\")\n        sqlContext.cacheTable(\"time_dim\") //缓存表\n        //    sqlContext.sql(\"select * from time_dim\").show;\n    \n        props += (\"dbtable\" -> \"source_dim\")\n    \n        jdbcDF = sqlContext.load(\"jdbc\", props.asJava) //加载注册多表\n        jdbcDF.registerTempTable(\"source_dim\")\n        sqlContext.cacheTable(\"source_dim\") //缓存表\n        //    sqlContext.sql(\"select * from source_dim\").show;\n    \n      }\n      def loadData(pathIn:String):Long={\n        val hadoopConf = sc.hadoopConfiguration\n        hadoopConf.set(\"io.compression.codec.snappy.native\", \"true\")//加载 日志样例\n        //val pathIn = \"oss://LTAIanYcMuGu2D3x:Nvqs7Fc82ygzAyv9BIVRpDK84nkMLv@trackstore.vpc100-oss-cn-beijing.aliyuncs.com/track_/2017/03/05/00/09_1488643787004340868_32297553.snappy\"\n        //val pathIn=\"oss://LTAIanYcMuGu2D3x:Nvqs7Fc82ygzAyv9BIVRpDK84nkMLv@tt-big-data.vpc100-oss-cn-beijing.aliyuncs.com/C-0A780AAFD528EF4E/172.16.2.113/log/http-request.log\"\n        //val pathIn = \"oss://logstash-json/track_/2017/06/0*/*\"//,oss://logstash-json/track_/2017/05/19/*\"//,oss://logstash-json/track_/2017/05/20/*\"//只支持一级目录下的文件，子目录不支持5\n        val inputData = sc.textFile(pathIn)\n        import sqlContext.implicits._\n        import sun.misc.{BASE64Encoder,BASE64Decoder}\n        import java.net.{URLDecoder,URLEncoder}\n        import scala.util.parsing.json.{JSON,JSONObject}\n    \n        //val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n        val spark = sqlContext\n        val df0 = spark.read.json(inputData)//.as[PV]\n        //df0.show()\n        val df=df0.select(\"data\")\n        // df.show\n        import org.apache.commons.lang3.StringEscapeUtils;\n        val data=df.map(t => t(0).toString.replace(\"=>\",\":\").replace(\"$\",\"\")).filter(t => \"\"!=t)//数据处理\n        val da=spark.read.json(data)\n        //da.show\n        da.registerTempTable(\"data\")//注册表\n        da.count\n        // sqlContext.cacheTable(\"data\")\n        // import java.text.SimpleDateFormat\n        //  import org.joda.time.format._\n        //  import org.joda.time._\n    \n        // import java.sql.Timestamp\n        // import org.apache.spark.sql._\n        // val da2=da.select(\"ip\",\"timestamp\")\n    \n    \n        // def ISODateToSqlDate (s:String):Timestamp={\n        //     var sdf:SimpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\")\n        //     Timestamp.valueOf(sdf.format(ISODateTimeFormat.dateTimeNoMillis().withZone(DateTimeZone.getDefault()).parseDateTime(s).toDate))\n        // }\n    \n    \n        // val da3=da2.rdd.map(s=>{(ISODateToSqlDate(s.getAs[String](\"timestamp\")),\"\"+s(0))})//red 处理并转dataFrame\n        // da3.toDF(\"timestamp\",\"ip\").show\n        // sqlContext.udf.register(\"ISODateToSqlDate\", (s: String) => ISODateToSqlDate(s))//二、注册自定义查询函数\n        // sqlContext.sql(\"select ip,ISODateToSqlDate(timestamp) st from data\").show\n    \n      }\n      def clearData()={\n        //da.count\n        // sqlContext.sql(\"\"\"\n        // select eventid--,timestamp,tkid,ssId,properties,version, regexp_replace(region_code,'%\\\\{\\\\[.*\\\\]\\\\}','') region_code,regexp_replace(addr,'%\\\\{\\\\[.*\\\\]\\\\}','') addr,ip\n        // from data\n        // where region_code is not null and token='lzlh' and type='track' and event='pageview'\n        // order by region_code\n        // \"\"\").count//数据清洗\n    \n        val da=sqlContext.sql(\"\"\"\n    select eventid,timestamp,tkid,ssId,properties,version, region_code,ip,\n    case when s.type is null and d.properties.referrer_host='' then \"其它\" when s.type is null and d.properties.referrer_host!='' then \"超级链接\" else s.type end as sourcetype,\n    case when s.source is null and d.properties.referrer_host='' then \"其它\" when s.source is null and d.properties.referrer_host!='' then d.properties.referrer_host else s.source end as source,\n    case when properties.model='pc' or properties.model='mac' then 'pc' else 'mobi' end as devicestype,\n    case when area[0] is null then '' else area[0] end country,\n    case when area[1] is null then '' else area[1] end province,\n    case when area[2] is null then '' else area[2] end city from(\n    select eventid,timestamp,tkid,ssId,properties,version, regexp_replace(region_code,\"%\\\\{\\\\[.*\\\\]\\\\[.*\\\\]\\\\}\",'') region_code,split(regexp_replace(addr,\"%\\\\{\\\\[.*\\\\]\\\\[.*\\\\]\\\\}\",''),\" \") area,ip\n    from data where token='lzlh' and type='track' and event='pageview'\n    ) d left join source_dim s on d.properties.referrer_host=s.match\n    \"\"\")\n        //da.count//数据清洗\n        da.registerTempTable(\"data\")//注册表\n      }","user":"ljj","dateUpdated":"2017-06-19T15:27:06+0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496919148559_-2042852488","id":"20170608-185228_1370456951","result":{"code":"SUCCESS","type":"TEXT","msg":"warning: there were 3 deprecation warning(s); re-run with -deprecation for details\nloadTim: ()Unit\nloadData: (pathIn: String)Long\nclearData: ()Unit\n"},"dateCreated":"2017-06-08T18:52:28+0800","dateStarted":"2017-06-19T15:27:06+0800","dateFinished":"2017-06-19T15:27:06+0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:191","focus":true},{"text":"    import com.stratio.datasource.mongodb.config.MongodbConfig._\n    import org.apache.spark.sql._\n    import com.stratio.datasource.mongodb._\n    import com.stratio.datasource.mongodb.config._\n\n    import org.apache.spark.sql.SQLContext\n    import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n    import sqlContext.implicits._\n    import java.text.SimpleDateFormat\n    import org.joda.time.format._\n    import org.joda.time._\n\n    import java.sql.Timestamp\n    \n def writeDayLevelNewOldVisitors(beforday:Int,overwriterflag:Int=0)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelNewOldVisitors\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n    res1.registerTempTable(\"DayLevelNewOldVisitors\")\n    //val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelNewOldVisitors\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    if(overwriterflag==0){\n        val da1=sqlContext.sql(\"select date_sub(now(),\"+beforday+\") date,c.tkid,case when d.isnew is null then 1 else 0 end isnew from (\"\n        +\"select distinct a.tkid from data a where substr(a.timestamp,1,10)=date_sub(now(),\"+beforday+\")) c \"\n        //+\"left join (select distinct tkid,0 isnew from data where substr(timestamp,1,10)<=date_sub(now(),\"+beforday+1+\")) d on d.tkid=c.tkid\"\n        +\"left join (select distinct tkid,0 isnew from DayLevelNewOldVisitors where date<=date_sub(now(),\"+beforday+1+\")) d on d.tkid=c.tkid\")//.show;\n    \n        da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n    }else{\n        val da1=sqlContext.sql(\"select date_sub(now(),\"+beforday+\") date,c.tkid,case when d.isnew is null then 1 else 0 end isnew from (\"\n        +\"select distinct a.tkid from data a where substr(a.timestamp,1,10)=date_sub(now(),\"+beforday+\")) c \"\n        +\"left join (select distinct tkid,0 isnew from data where substr(timestamp,1,10)<=date_sub(now(),\"+beforday+1+\")) d on d.tkid=c.tkid\")\n        //+\"left join (select distinct tkid,0 isnew from DayLevelNewOldVisitors where date<=date_sub(now(),\"+beforday+1+\")) d on d.tkid=c.tkid\")//.show;\n    \n        da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Overwrite).options(opt).save()\n        \n    }\n    //val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n    //res1.show\n    //res1.registerTempTable(\"DayLevelNewOldVisitors\")\n  }\ndef writeDayLevelNewOldVisitorsIndicators(beforday:Int)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelNewOldVisitors\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n    res1.registerTempTable(\"DayLevelNewOldVisitors\")\n    val opt1=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelNewOldVisitorsIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    var da1=sqlContext.sql(s\"\"\"\nselect date_sub(now(),$beforday) date ,isnew,source,devicestype,province,count(distinct d.eventid) as pv,count(distinct d.ssid) as sv ,count(distinct d.ip) ips,count(distinct d.tkid) uv\nfrom DayLevelNewOldVisitors a left join data d on a.tkid=d.tkid and substr(d.timestamp,1,10)=date_sub(now(),$beforday) and a.date=date_sub(now(),$beforday)\ngroup by isnew,source,devicestype,province\n\"\"\")//.show\n\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt1).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n def writeDayLevelIndicators(beforday:Int)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect t.y,t.q,t.m,t.w,t.date date,d.source,d.devicestype,d.province,count(distinct d.eventid) as pv,count(distinct d.ssid) as sv ,count(distinct d.ip) ips,count(distinct d.tkid) uv \nfrom data d \nright join date_dim t on substr(d.timestamp,1,10)=t.date and t.date=date_sub(now(),$beforday) \nwhere substr(d.timestamp,1,10) = date_sub(now(),$beforday) \ngroup by t.y,t.q,t.m,t.w,t.date,d.source,d.devicestype,d.province\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n    def writeDayLevelSourceIndicators(beforday:Int)={\n    // val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"SourceIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelSourceIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect date_sub(now(),$beforday) date,sourcetype ,source,devicestype,province,count(distinct d.eventid) as pv,count(distinct d.ssid) as sv ,count(distinct d.ip) ips,count(distinct tkid) uv\nfrom data d WHERE substr(d.timestamp,1,10)=date_sub(now(),$beforday)\n--left join date_dim on substr(timestamp,1,10)=date_dim.date and date_dim.date=date_sub(now(),$beforday)  --join维度表\ngroup by sourcetype,source,devicestype,province\n\"\"\")//.show;\n\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def writeDayLevelDevicesIndicators(beforday:Int)={\n    // val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DevicesIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelDevicesIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect date_sub(now(),$beforday) date,devicestype,province,properties.model,properties.os,count(distinct d.eventid) as pv,count(distinct d.ssid) as sv ,count(distinct d.ip) ips,count(distinct tkid) uv\nfrom data d where substr(d.timestamp,1,10)=date_sub(now(),$beforday)\n--left join date_dim on substr(timestamp,1,10)=date_dim.date and date_dim.date=date_sub(now(),$beforday)  --join维度表\ngroup by properties.os,properties.model,devicestype,province\n\"\"\")//.show;\n\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def ISODateToSqlDate (s:String):Timestamp={\n    var sdf:SimpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\")\n    Timestamp.valueOf(sdf.format(ISODateTimeFormat.dateTimeNoMillis().withZone(DateTimeZone.getDefault()).parseDateTime(s).toDate))\n  }\n  def writeTrackpageview(beforday:Int)={\n    // import com.stratio.datasource.mongodb.config.MongodbConfig._\n    // import org.apache.spark.sql._\n    // import com.stratio.datasource.mongodb._\n    // import com.stratio.datasource.mongodb.config._\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"trackpageview\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    //http://blog.csdn.net/liuguangfudan/article/details/53304368 内置函数\n\n//    def ISODateToSqlDate (s:String):Timestamp={\n//      var sdf:SimpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\")\n//      Timestamp.valueOf(sdf.format(ISODateTimeFormat.dateTimeNoMillis().withZone(DateTimeZone.getDefault()).parseDateTime(s).toDate))\n//    }\n    // val da3=da2.map(s=>{(ISODateToSqlDate(s.getAs[String](\"timestamp\")),\"\"+s(0))})\n    // da3.toDF(\"timestamp\",\"date\").show\n\n//    sqlContext.udf.register(\"ISODateToSqlDate\", (s: String) => ISODateToSqlDate(s))\n     val da1=sqlContext.sql(s\"select ISODateToSqlDate(timestamp) st,* from data where substr(timestamp,1,10)=date_sub(now(),$beforday)\")\n     da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def writeHourLevelIndicators(beforday:Int)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"HourLevelIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect date_sub(now(),$beforday) date,t1.time,source,devicestype,province,count(t2.eventid) pv,count(distinct t2.ssid) sv ,count(distinct t2.ip) ips,count(distinct tkid) uv from\n(select eventid,ssid,source,devicestype,province,timestamp,ip,tkid from data where substr(timestamp,1,10)=date_sub(now(),$beforday)) t2 right join time_dim t1 on t1.time=substr(timestamp,12,2)\ngroup by t1.time,date_sub(now(),$beforday),source,devicestype,province\norder by t1.time\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def writeDayLevelRegionIndicators(beforday:Int)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelRegionIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect date_sub(now(),$beforday) date,province,count(eventid) pv,count(distinct ssId) sv,count(distinct ip) ips,count(distinct tkid) uv\nfrom data where substr(timestamp,1,10)=date_sub(now(),$beforday)\n--left join date_dim on substr(timestamp,1,10)=date_dim.date and date_dim.date=date_sub(now(),$beforday)  --join维度表\ngroup by province\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def writePVLongIndicators(beforday:Int)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"PVLongIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect date_sub(now(),$beforday) date,tkid,sourcetype,source,devicestype,province,ssId ssid,count(ssid) p,max(unix_timestamp(ISODateToSqlDate(timestamp)))-min(unix_timestamp(ISODateToSqlDate(timestamp))) vstimes ,(max(unix_timestamp(ISODateToSqlDate(timestamp)))-min(unix_timestamp(ISODateToSqlDate(timestamp))))/count(ssid) avgpagevstimes\nfrom data \nwhere substr(timestamp,1,10)=date_sub(now(),$beforday)\n--left join date_dim on substr(timestamp,1,10)=date_dim.date and date_dim.date=date_sub(now(),$beforday)  --join维度表\ngroup by ssId,date_sub(now(),$beforday),tkid,sourcetype,source,devicestype,province order by date_sub(now(),$beforday) desc\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  \ndef writeDayLevelPageIndicators(beforday:Int)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelPageIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect first(date) date,url,source,devicestype,province,count(eventid) pagepv,count(distinct tkid) pageuv,count(distinct ssid) pagenum,count(distinct ip) ips,count(distinct ssid)/count(distinct tkid) avgssidpagenum--,sum(vstimes)/count(distinct ssid) avgvstimes--,count(case when p=1 and n=1 then p end)/count(distinct ssid)*100 jumpv\nfrom (\n    -- select a.date,a.ssid,a.url,count(a.ssid) p,a.tkid,a.ip,unix_timestamp(ISODateToSqlDate(last(a.timestamp)))-unix_timestamp(ISODateToSqlDate(first(a.timestamp))) vstimes\n    -- from (\n        select eventid,date_sub(now(),$beforday) date,ssId ssid,source,devicestype,province,properties.url,properties.url_domain,tkid,ip,timestamp\n        from data\n        where substr(timestamp,1,10) = date_sub(now(),$beforday)\n        --left join date_dim on substr(timestamp,1,10)=date_dim.date and date_dim.date=date_sub(now(),$beforday)  --join维度表\n        order by timestamp asc\n    -- ) a\n    -- group by a.ssid,a.date,a.url,a.tkid,a.ip\n) b\ngroup by url,source,devicestype,province\norder by pagepv desc\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def writeDayLevelFirstPageIndicators(beforday:Int)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelFirstPageIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect first(b.date) date,firsturl,source,devicestype,province,sum(p) firstpagepv,count(distinct tkid) firstpageuv,count(firsturl) firstpagenum,count(distinct ip) ips,count(firsturl)/count(distinct tkid) avgpagenum,sum(vstimes)/count(firsturl) avgvstimes,count(case p when 1 then p end)/count(firsturl)*100 jumpv\nfrom (\n    select a.date date,a.source,a.devicestype,a.province,a.ssid,first(case when a.url_domain='twotiger.com' then url end) firsturl, last(case when a.url_domain='twotiger.com' then url end) lasturl,count(a.ssid) p,a.tkid,a.ip,unix_timestamp(ISODateToSqlDate(last(a.timestamp)))-unix_timestamp(ISODateToSqlDate(first(a.timestamp))) vstimes\n    from (\n        select date_sub(now(),$beforday) date,source,devicestype,province,ssId ssid,properties.url,properties.url_domain,tkid,ip,timestamp\n        from data \n        where substr(timestamp,1,10) = date_sub(now(),$beforday)\n        --left join date_dim on substr(timestamp,1,10)=date_dim.date and date_dim.date=date_sub(now(),$beforday)  --join维度表\n        order by timestamp asc\n    ) a\n    group by a.ssid,a.date,a.tkid,a.ip,a.source,a.devicestype,a.province\n    having firsturl is not null\n) b\ngroup by firsturl,source,devicestype,province\norder by firstpagepv desc\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def writeDayLevelLastPageIndicators(beforday:Int)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"DayLevelLastPageIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect first(b.date) date,lasturl,source,devicestype,province,sum(p) lastpagepv,count(distinct tkid) lastpageuv,count(lasturl) lastpagenum,count(distinct ip) ips,count(lasturl)/count(distinct tkid) avgpagenum,sum(vstimes)/count(lasturl) avgvstimes,count(case p when 1 then p end)/count(lasturl)*100 jumpv\nfrom (\n    select a.date,a.source,a.devicestype,a.province,a.ssid,first(case when a.date='twotiger.com' then url end) firsturl, last(case when a.url_domain='twotiger.com' then url end) lasturl,count(a.ssid) p,a.tkid,a.ip,unix_timestamp(ISODateToSqlDate(last(a.timestamp)))-unix_timestamp(ISODateToSqlDate(first(a.timestamp))) vstimes\n    from (\n        select date_sub(now(),$beforday) date,source,devicestype,province,ssId ssid,properties.url,properties.url_domain,tkid,ip,timestamp\n        from data \n        where substr(timestamp,1,10)=date_sub(now(),$beforday)\n        --left join date_dim on substr(timestamp,1,10)=date_dim.date and date_dim.date=date_sub(now(),$beforday)  --join维度表\n        order by timestamp asc\n    ) a\n    group by a.ssid,a.date,a.tkid,a.ip,a.source,a.devicestype,a.province\n    having lasturl is not null\n) b\ngroup by lasturl,source,devicestype,province\norder by lastpagepv desc\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def writepvProfile()={\n    var opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"HourLevelIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n    res1.registerTempTable(\"HourLevelIndicators\")\n    opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"pvProfile\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(\"\"\"\nselect 'today' as date,sum(pv) pv,sum(sv) sv,sum(ips) ips,sum(uv) uv from HourLevelIndicators where date = date_sub(now(),0)\nunion all\nselect 'yesterday' as date,sum(pv) pv,sum(sv) sv,sum(ips) ips,sum(uv) uv from HourLevelIndicators where date = date_sub(now(),1)\nunion all\nselect t1.date,round(t1.pv*t2.pv,0) pv,round(t1.sv*t2.sv,0) sv,round(t1.ips*t2.ips,0) ips,round(t1.uv*t2.uv,0) uv from\n(select 'forecast' as date,sum(pv) pv,sum(sv) sv,sum(ips) ips,sum(uv) uv from HourLevelIndicators where date = date_sub(now(),0)) t1,\n(\n    select sum(case when pv is not null then pv end)/(case when sum(case when hour<=hour(now()) and pv is not null  then pv end ) is null  then 1 else sum(case when hour<=hour(now()) and pv is not null  then pv end ) end ) pv,\n    sum(case when sv is not null then sv end)/(case when sum(case when hour<=hour(now()) and sv is not null  then sv end ) is null  then 1 else sum(case when hour<=hour(now()) and sv is not null  then sv end ) end ) sv,\n    sum(case when uv is not null then uv end)/(case when sum(case when hour<=hour(now()) and uv is not null  then uv end ) is null  then 1 else sum(case when hour<=hour(now()) and uv is not null  then uv end ) end ) uv ,\n    sum(case when ips is not null then ips end)/(case when sum(case when hour<=hour(now()) and ips is not null  then ips end ) is null  then 1 else sum(case when hour<=hour(now()) and ips is not null  then ips end ) end ) ips from\n        (select time hour,sum(pv) pv,sum(sv) sv,sum(ips) ips,sum(uv) uv from HourLevelIndicators where date>= date_sub(now(),7) and date<= date_sub(now(),1) group by time) a\n) t2\nunion all\nselect 'yesterdaythistime' as date,sum(pv) pv,sum(sv) sv,sum(ips) ips,sum(uv) uv from HourLevelIndicators where date = date_sub(now(),1) and time<=hour(now())\n--union all\n--select 'total' as date,sum(pv) pv,sum(sv) sv,sum(ips) ips,sum(uv) uv from (select sum(pv) pv,sum(sv) sv,sum(ips) ips,sum(uv) uv from HourLevelIndicators where date >= date_sub(now(),6) group by date) t\nunion all\nselect 'dayavg' as date,avg(pv) pv,avg(sv) sv,avg(ips) ips,avg(uv) uv from (select sum(pv) pv,sum(sv) sv,sum(ips) ips,sum(uv) uv from HourLevelIndicators where date >= date_sub(now(),6) group by date) t\nunion all\nselect 'daymax' as date,max(pv) pv,max(sv) sv,max(ips) ips,max(uv) uv from (select sum(pv) pv,sum(sv) sv,sum(ips) ips,sum(uv) uv from HourLevelIndicators where date >= date_sub(now(),6) group by date) t\n--union all\n--select 'daymin' as date,min(pv) pv,min(sv) sv,min(ips) ips,min(uv) uv from (select sum(pv) pv,sum(sv) sv,sum(ips) ips,sum(uv) uv from HourLevelIndicators where date >= date_sub(now(),6) group by date) t\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Overwrite).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def writeWeekLevelIndicators(beforday:Int)={\n    // val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"WeekLevelIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    // val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n    // res1.registerTempTable(\"WeekLevelIndicators\")\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"WeekLevelIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect t.y,t.w,t.date date,d.source,d.devicestype,d.province,count(distinct d.eventid) as pv,count(distinct d.ssid) as sv ,count(distinct d.ip) ips,count(distinct d.tkid) uv \nfrom data d \nright join date_dim t on substr(d.timestamp,1,10)=t.date and t.date=date_sub(now(),$beforday) \nwhere substr(d.timestamp,1,10) = date_sub(now(),$beforday) \ngroup by t.y,t.w,t.date,d.source,d.devicestype,d.province\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def writeMonthLevelIndicators(beforday:Int)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"MonthLevelIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect t.y,t.m,t.date date,d.source,d.devicestype,d.province,count(distinct d.eventid) as pv,count(distinct d.ssid) as sv ,count(distinct d.ip) ips,count(distinct d.tkid) uv \nfrom data d \nright join date_dim t on substr(d.timestamp,1,10)=t.date and t.date=date_sub(now(),$beforday) \nwhere substr(d.timestamp,1,10) = date_sub(now(),$beforday) \ngroup by t.y,t.m,t.date,d.source,d.devicestype,d.province\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n  def writeQuarterLevelIndicators(beforday:Int)={\n    val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"QuarterLevelIndicators\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(s\"\"\"\nselect t.y,t.q,t.date date,d.source,d.devicestype,d.province,count(distinct d.eventid) as pv,count(distinct d.ssid) as sv ,count(distinct d.ip) ips,count(distinct d.tkid) uv \nfrom data d \nright join date_dim t on substr(d.timestamp,1,10)=t.date and t.date=date_sub(now(),$beforday) \nwhere substr(d.timestamp,1,10) = date_sub(now(),$beforday) \ngroup by t.y,t.q,t.date,d.source,d.devicestype,d.province\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Append).options(opt).save()\n//     select t.y,t.q,t.date date,d.source,d.devicestype,d.province,count(distinct d.eventid) as pv,count(distinct d.ssid) as sv ,count(distinct d.ip) ips,count(distinct d.tkid) uv \n// from data d --(select timestamp,source,devicestype,province,eventid,ssid,ip,tkid from data where substr(timestamp,1,10) = date_sub(now(),11)) d \n// right join date_dim t on substr(d.timestamp,1,10)=t.date and t.date=date_sub(now(),11) \n// where substr(d.timestamp,1,10) = date_sub(now(),11)\n// group by t.y,t.q,t.date,d.source,d.devicestype,d.province\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show\n  }\n// def dayLevelAppend(beforday:Int)= {\n//     writeTrackpageview(beforday)\n//     writePVLongIndicators(beforday)\n\n//     writeDayLevelNewOldVisitors(beforday)\n//     writeDayLevelNewOldVisitorsIndicators(beforday)\n\n//     writeDayLevelSourceIndicators(beforday)\n//     writeDayLevelDevicesIndicators(beforday)\n//     writeDayLevelIndicators(beforday)\n//     writeHourLevelIndicators(beforday)\n\n//     writeDayLevelRegionIndicators(beforday)\n//     writeDayLevelPageIndicators(beforday)\n//     writeDayLevelFirstPageIndicators(beforday)\n//     writeDayLevelLastPageIndicators(beforday)\n//   }\n ","user":"ljj","dateUpdated":"2017-06-19T15:27:24+0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496919269566_-745278339","id":"20170608-185429_134880243","result":{"code":"SUCCESS","type":"TEXT","msg":"import com.stratio.datasource.mongodb.config.MongodbConfig._\nimport org.apache.spark.sql._\nimport com.stratio.datasource.mongodb._\nimport com.stratio.datasource.mongodb.config._\nimport org.apache.spark.sql.SQLContext\nimport org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\nimport sqlContext.implicits._\nimport java.text.SimpleDateFormat\nimport org.joda.time.format._\nimport org.joda.time._\nimport java.sql.Timestamp\nwriteDayLevelNewOldVisitors: (beforday: Int, overwriterflag: Int)Unit\nwriteDayLevelNewOldVisitorsIndicators: (beforday: Int)Unit\nwriteDayLevelIndicators: (beforday: Int)Unit\nwriteDayLevelSourceIndicators: (beforday: Int)Unit\nwriteDayLevelDevicesIndicators: (beforday: Int)Unit\nISODateToSqlDate: (s: String)java.sql.Timestamp\nwriteTrackpageview: (beforday: Int)Unit\nwriteHourLevelIndicators: (beforday: Int)Unit\nwriteDayLevelRegionIndicators: (beforday: Int)Unit\nwritePVLongIndicators: (beforday: Int)Unit\nwriteDayLevelPageIndicators: (beforday: Int)Unit\nwriteDayLevelFirstPageIndicators: (beforday: Int)Unit\nwriteDayLevelLastPageIndicators: (beforday: Int)Unit\nwritepvProfile: ()Unit\nwriteWeekLevelIndicators: (beforday: Int)Unit\nwriteMonthLevelIndicators: (beforday: Int)Unit\nwriteQuarterLevelIndicators: (beforday: Int)Unit\n"},"dateCreated":"2017-06-08T18:54:29+0800","dateStarted":"2017-06-19T15:27:24+0800","dateFinished":"2017-06-19T15:27:29+0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:192","focus":true},{"text":" def dayLevelAppend(beforday:Int)= {\n         \n    import org.apache.spark.sql.SQLContext\n    import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n    import sqlContext.implicits._\n\n    println(\"track begin:writeTrackpageview\")\n    writeTrackpageview(beforday)\n    println(\"track end:writeTrackpageview\")\n    println(\"track begin:writePVLongIndicators\")\n    writePVLongIndicators(beforday)\n    println(\"track end:writePVLongIndicators\")\n\n    println(\"track begin:writeDayLevelNewOldVisitors\")\n    writeDayLevelNewOldVisitors(beforday)\n    println(\"track end:writeDayLevelNewOldVisitors\")\n    println(\"track begin:writeDayLevelNewOldVisitorsIndicators\")\n    writeDayLevelNewOldVisitorsIndicators(beforday)\n    println(\"track end:writeDayLevelNewOldVisitorsIndicators\")\n\n    println(\"track begin:writeDayLevelSourceIndicators\")\n    writeDayLevelSourceIndicators(beforday)\n    println(\"track end:writeDayLevelSourceIndicators\")\n    println(\"track begin:writeDayLevelDevicesIndicators\")\n    writeDayLevelDevicesIndicators(beforday)\n    println(\"track end:writeDayLevelDevicesIndicators\")\n    println(\"track begin:writeDayLevelIndicators\")\n    writeDayLevelIndicators(beforday)\n    println(\"track end:writeDayLevelIndicators\")\n    println(\"track begin:writeHourLevelIndicators\")\n    writeHourLevelIndicators(beforday)\n    println(\"track end:writeHourLevelIndicators\")\n\n    println(\"track begin:writeDayLevelRegionIndicators\")\n    writeDayLevelRegionIndicators(beforday)\n    println(\"track end:writeDayLevelRegionIndicators\")\n    println(\"track begin:writeDayLevelPageIndicators\")\n    writeDayLevelPageIndicators(beforday)\n    println(\"track end:writeDayLevelPageIndicators\")\n    println(\"track begin:writeDayLevelFirstPageIndicators\")\n    writeDayLevelFirstPageIndicators(beforday)\n    println(\"track end:writeDayLevelFirstPageIndicators\")\n    println(\"track begin:writeDayLevelLastPageIndicators\")\n    writeDayLevelLastPageIndicators(beforday)\n    println(\"track end:writeDayLevelLastPageIndicators\")\n  }\n //date格式yyyy-MM-dd HH:mm:ss,level三种： d|h|m分别代表天时分级\ndef getPathIn(datestr:String=null,level:String=\"h\"):String={\n    import java.util.Calendar\n    import java.util.Date\n    import java.text.SimpleDateFormat\n    var format = new SimpleDateFormat(\"yyyy-MM-dd HH:mm\");\n    var date=new Date()\n    if(datestr != null){\n      date = format.parse(datestr);\n    }\n    var toFormat: SimpleDateFormat = new SimpleDateFormat(\"yyyy/MM/dd\")\n    var pathIn = \"oss://logstash-json/track_/\"\n\n    if(level==\"h\"){\n      toFormat= new SimpleDateFormat(\"yyyy/MM/dd/HH\")\n      pathIn+=toFormat.format(date)+\"/*\"\n    }else if(level==\"m\"){\n      toFormat = new SimpleDateFormat(\"yyyy/MM/dd/HH/mm\")\n      pathIn+=toFormat.format(date)+\"*\"\n    }else{\n      toFormat = new SimpleDateFormat(\"yyyy/MM/dd\")\n      pathIn+=toFormat.format(date)+\"/*\"\n    }\n    println(\"track begin:\"+pathIn)\n    pathIn\n  }\n  def befordays(datestr:String=null):Int={\n    if(datestr==null){0}else {\n      import java.util.Calendar\n      import java.util.Date\n      import java.text.SimpleDateFormat\n      var format = new SimpleDateFormat(\"yyyy-MM-dd\");\n      var date = format.parse(datestr);\n      // 计算日期间隔天数\n      val diff = new Date().getTime() - date.getTime()\n      (diff / (1000 * 60 * 60 * 24)).toInt\n    }\n  }","user":"ljj","dateUpdated":"2017-06-19T15:27:32+0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1497018059674_-1082347215","id":"20170609-222059_894996860","result":{"code":"SUCCESS","type":"TEXT","msg":"dayLevelAppend: (beforday: Int)Unit\ngetPathIn: (datestr: String, level: String)String\nbefordays: (datestr: String)Int\n"},"dateCreated":"2017-06-09T22:20:59+0800","dateStarted":"2017-06-19T15:27:32+0800","dateFinished":"2017-06-19T15:27:32+0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:193","focus":true},{"text":"var i=4\nfor(i <- 3 to 9){\n    val date=\"2017-06-1\"+i+\" 00:00\"\n    println(date)\n\n    loadTim\n    if(loadData(getPathIn(date,\"d\"))>0){\n        clearData\n        \n        import sqlContext.implicits._\n        sqlContext.udf.register(\"ISODateToSqlDate\", (s: String) => ISODateToSqlDate(s))\n        \n        // var beforday=befordays(date)\n        //writeTrackpageview(beforday)\n        //writePVLongIndicators(beforday)\n    \n        // writeDayLevelNewOldVisitors(beforday,1)\n        // writeDayLevelNewOldVisitorsIndicators(beforday)\n    \n        // writeDayLevelSourceIndicators(beforday)\n        // writeDayLevelDevicesIndicators(beforday)\n        // writeDayLevelIndicators(beforday)\n        // writeHourLevelIndicators(beforday)\n    \n        // writeDayLevelRegionIndicators(beforday)\n        // writeDayLevelPageIndicators(beforday)\n        // writeDayLevelFirstPageIndicators(beforday)\n        // writeDayLevelLastPageIndicators(beforday)\n        \n        dayLevelAppend(befordays(date))\n        println(\"track begin:writepvProfile\")    \n        writepvProfile\n        println(\"track end:writepvProfile\")    \n        // writeWeekLevelIndicators(befordays(date))\n        // writeMonthLevelIndicators(befordays(date))\n        // writeQuarterLevelIndicators(befordays(date))\n    }\n}","user":"ljj","dateUpdated":"2017-06-19T15:29:42+0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1497326102649_-2062454964","id":"20170613-115502_1785558437","result":{"code":"SUCCESS","type":"TEXT","msg":"i: Int = 4\n2017-06-13 00:00\ntrack begin:oss://logstash-json/track_/2017/06/13/*\ntrack begin:writeTrackpageview\ntrack end:writeTrackpageview\ntrack begin:writePVLongIndicators\ntrack end:writePVLongIndicators\ntrack begin:writeDayLevelNewOldVisitors\ntrack end:writeDayLevelNewOldVisitors\ntrack begin:writeDayLevelNewOldVisitorsIndicators\ntrack end:writeDayLevelNewOldVisitorsIndicators\ntrack begin:writeDayLevelSourceIndicators\ntrack end:writeDayLevelSourceIndicators\ntrack begin:writeDayLevelDevicesIndicators\ntrack end:writeDayLevelDevicesIndicators\ntrack begin:writeDayLevelIndicators\ntrack end:writeDayLevelIndicators\ntrack begin:writeHourLevelIndicators\ntrack end:writeHourLevelIndicators\ntrack begin:writeDayLevelRegionIndicators\ntrack end:writeDayLevelRegionIndicators\ntrack begin:writeDayLevelPageIndicators\ntrack end:writeDayLevelPageIndicators\ntrack begin:writeDayLevelFirstPageIndicators\ntrack end:writeDayLevelFirstPageIndicators\ntrack begin:writeDayLevelLastPageIndicators\ntrack end:writeDayLevelLastPageIndicators\ntrack begin:writepvProfile\ntrack end:writepvProfile\n2017-06-14 00:00\ntrack begin:oss://logstash-json/track_/2017/06/14/*\ntrack begin:writeTrackpageview\ntrack end:writeTrackpageview\ntrack begin:writePVLongIndicators\ntrack end:writePVLongIndicators\ntrack begin:writeDayLevelNewOldVisitors\ntrack end:writeDayLevelNewOldVisitors\ntrack begin:writeDayLevelNewOldVisitorsIndicators\ntrack end:writeDayLevelNewOldVisitorsIndicators\ntrack begin:writeDayLevelSourceIndicators\ntrack end:writeDayLevelSourceIndicators\ntrack begin:writeDayLevelDevicesIndicators\ntrack end:writeDayLevelDevicesIndicators\ntrack begin:writeDayLevelIndicators\ntrack end:writeDayLevelIndicators\ntrack begin:writeHourLevelIndicators\ntrack end:writeHourLevelIndicators\ntrack begin:writeDayLevelRegionIndicators\ntrack end:writeDayLevelRegionIndicators\ntrack begin:writeDayLevelPageIndicators\ntrack end:writeDayLevelPageIndicators\ntrack begin:writeDayLevelFirstPageIndicators\ntrack end:writeDayLevelFirstPageIndicators\ntrack begin:writeDayLevelLastPageIndicators\ntrack end:writeDayLevelLastPageIndicators\ntrack begin:writepvProfile\ntrack end:writepvProfile\n2017-06-15 00:00\ntrack begin:oss://logstash-json/track_/2017/06/15/*\ntrack begin:writeTrackpageview\ntrack end:writeTrackpageview\ntrack begin:writePVLongIndicators\ntrack end:writePVLongIndicators\ntrack begin:writeDayLevelNewOldVisitors\ntrack end:writeDayLevelNewOldVisitors\ntrack begin:writeDayLevelNewOldVisitorsIndicators\ntrack end:writeDayLevelNewOldVisitorsIndicators\ntrack begin:writeDayLevelSourceIndicators\ntrack end:writeDayLevelSourceIndicators\ntrack begin:writeDayLevelDevicesIndicators\ntrack end:writeDayLevelDevicesIndicators\ntrack begin:writeDayLevelIndicators\ntrack end:writeDayLevelIndicators\ntrack begin:writeHourLevelIndicators\ntrack end:writeHourLevelIndicators\ntrack begin:writeDayLevelRegionIndicators\ntrack end:writeDayLevelRegionIndicators\ntrack begin:writeDayLevelPageIndicators\ntrack end:writeDayLevelPageIndicators\ntrack begin:writeDayLevelFirstPageIndicators\ntrack end:writeDayLevelFirstPageIndicators\ntrack begin:writeDayLevelLastPageIndicators\ntrack end:writeDayLevelLastPageIndicators\ntrack begin:writepvProfile\ntrack end:writepvProfile\n2017-06-16 00:00\ntrack begin:oss://logstash-json/track_/2017/06/16/*\ntrack begin:writeTrackpageview\ntrack end:writeTrackpageview\ntrack begin:writePVLongIndicators\ntrack end:writePVLongIndicators\ntrack begin:writeDayLevelNewOldVisitors\ntrack end:writeDayLevelNewOldVisitors\ntrack begin:writeDayLevelNewOldVisitorsIndicators\ntrack end:writeDayLevelNewOldVisitorsIndicators\ntrack begin:writeDayLevelSourceIndicators\ntrack end:writeDayLevelSourceIndicators\ntrack begin:writeDayLevelDevicesIndicators\ntrack end:writeDayLevelDevicesIndicators\ntrack begin:writeDayLevelIndicators\ntrack end:writeDayLevelIndicators\ntrack begin:writeHourLevelIndicators\ntrack end:writeHourLevelIndicators\ntrack begin:writeDayLevelRegionIndicators\ntrack end:writeDayLevelRegionIndicators\ntrack begin:writeDayLevelPageIndicators\ntrack end:writeDayLevelPageIndicators\ntrack begin:writeDayLevelFirstPageIndicators\ntrack end:writeDayLevelFirstPageIndicators\ntrack begin:writeDayLevelLastPageIndicators\ntrack end:writeDayLevelLastPageIndicators\ntrack begin:writepvProfile\ntrack end:writepvProfile\n2017-06-17 00:00\ntrack begin:oss://logstash-json/track_/2017/06/17/*\ntrack begin:writeTrackpageview\ntrack end:writeTrackpageview\ntrack begin:writePVLongIndicators\ntrack end:writePVLongIndicators\ntrack begin:writeDayLevelNewOldVisitors\ntrack end:writeDayLevelNewOldVisitors\ntrack begin:writeDayLevelNewOldVisitorsIndicators\ntrack end:writeDayLevelNewOldVisitorsIndicators\ntrack begin:writeDayLevelSourceIndicators\ntrack end:writeDayLevelSourceIndicators\ntrack begin:writeDayLevelDevicesIndicators\ntrack end:writeDayLevelDevicesIndicators\ntrack begin:writeDayLevelIndicators\ntrack end:writeDayLevelIndicators\ntrack begin:writeHourLevelIndicators\ntrack end:writeHourLevelIndicators\ntrack begin:writeDayLevelRegionIndicators\ntrack end:writeDayLevelRegionIndicators\ntrack begin:writeDayLevelPageIndicators\ntrack end:writeDayLevelPageIndicators\ntrack begin:writeDayLevelFirstPageIndicators\ntrack end:writeDayLevelFirstPageIndicators\ntrack begin:writeDayLevelLastPageIndicators\ntrack end:writeDayLevelLastPageIndicators\ntrack begin:writepvProfile\ntrack end:writepvProfile\n2017-06-18 00:00\ntrack begin:oss://logstash-json/track_/2017/06/18/*\ntrack begin:writeTrackpageview\ntrack end:writeTrackpageview\ntrack begin:writePVLongIndicators\ntrack end:writePVLongIndicators\ntrack begin:writeDayLevelNewOldVisitors\ntrack end:writeDayLevelNewOldVisitors\ntrack begin:writeDayLevelNewOldVisitorsIndicators\ntrack end:writeDayLevelNewOldVisitorsIndicators\ntrack begin:writeDayLevelSourceIndicators\ntrack end:writeDayLevelSourceIndicators\ntrack begin:writeDayLevelDevicesIndicators\ntrack end:writeDayLevelDevicesIndicators\ntrack begin:writeDayLevelIndicators\ntrack end:writeDayLevelIndicators\ntrack begin:writeHourLevelIndicators\ntrack end:writeHourLevelIndicators\ntrack begin:writeDayLevelRegionIndicators\ntrack end:writeDayLevelRegionIndicators\ntrack begin:writeDayLevelPageIndicators\ntrack end:writeDayLevelPageIndicators\ntrack begin:writeDayLevelFirstPageIndicators\ntrack end:writeDayLevelFirstPageIndicators\ntrack begin:writeDayLevelLastPageIndicators\ntrack end:writeDayLevelLastPageIndicators\ntrack begin:writepvProfile\ntrack end:writepvProfile\n2017-06-19 00:00\ntrack begin:oss://logstash-json/track_/2017/06/19/*\ntrack begin:writeTrackpageview\ntrack end:writeTrackpageview\ntrack begin:writePVLongIndicators\ntrack end:writePVLongIndicators\ntrack begin:writeDayLevelNewOldVisitors\ntrack end:writeDayLevelNewOldVisitors\ntrack begin:writeDayLevelNewOldVisitorsIndicators\ntrack end:writeDayLevelNewOldVisitorsIndicators\ntrack begin:writeDayLevelSourceIndicators\ntrack end:writeDayLevelSourceIndicators\ntrack begin:writeDayLevelDevicesIndicators\ntrack end:writeDayLevelDevicesIndicators\ntrack begin:writeDayLevelIndicators\ntrack end:writeDayLevelIndicators\ntrack begin:writeHourLevelIndicators\ntrack end:writeHourLevelIndicators\ntrack begin:writeDayLevelRegionIndicators\ntrack end:writeDayLevelRegionIndicators\ntrack begin:writeDayLevelPageIndicators\ntrack end:writeDayLevelPageIndicators\ntrack begin:writeDayLevelFirstPageIndicators\ntrack end:writeDayLevelFirstPageIndicators\ntrack begin:writeDayLevelLastPageIndicators\ntrack end:writeDayLevelLastPageIndicators\ntrack begin:writepvProfile\ntrack end:writepvProfile\n"},"dateCreated":"2017-06-13T11:55:02+0800","dateStarted":"2017-06-19T15:29:42+0800","dateFinished":"2017-06-19T15:48:37+0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:194","focus":true},{"text":"var date=null\n// var i=0\n// for(i <- 0 to 2\n// ){\n//     date=\"2017-06-13 1\"+i+\":00\"\n//     println(date)\n\n    loadTim\n    if(loadData(getPathIn())>0){\n        clearData\n        \n        import sqlContext.implicits._\n        sqlContext.udf.register(\"ISODateToSqlDate\", (s: String) => ISODateToSqlDate(s))\n        \n        var beforday=befordays(date)\n        writeTrackpageview(beforday)\n        //writePVLongIndicators(beforday)\n    \n        // writeDayLevelNewOldVisitors(beforday,1)\n        // writeDayLevelNewOldVisitorsIndicators(beforday)\n    \n        // writeDayLevelSourceIndicators(beforday)\n        // writeDayLevelDevicesIndicators(beforday)\n        // writeDayLevelIndicators(beforday)\n        // writeHourLevelIndicators(beforday)\n    \n        // writeDayLevelRegionIndicators(beforday)\n        // writeDayLevelPageIndicators(beforday)\n        // writeDayLevelFirstPageIndicators(beforday)\n        // writeDayLevelLastPageIndicators(beforday)\n        \n            // dayLevelAppend(befordays())\n            // println(\"track begin:writepvProfile\")\n            // writepvProfile\n            // println(\"track end:writepvProfile\")    \n        \n        // writeWeekLevelIndicators(befordays(date))\n        // writeMonthLevelIndicators(befordays(date))\n        // writeQuarterLevelIndicators(befordays(date))\n    }\n// }","user":"ljj","dateUpdated":"2017-06-19T10:47:10+0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496919267942_201573380","id":"20170608-185427_406710730","result":{"code":"SUCCESS","type":"TEXT","msg":"date: Null = null\ntrack begin:oss://logstash-json/track_/2017/06/19/10/*\n"},"dateCreated":"2017-06-08T18:54:27+0800","dateStarted":"2017-06-19T10:47:10+0800","dateFinished":"2017-06-19T10:47:14+0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:195","focus":true},{"text":"%sql\nselect * from data\n-- select t.y,t.q,t.date date,d.source,d.devicestype,d.province,count(distinct d.eventid) as pv,count(distinct d.ssid) as sv ,count(distinct d.ip) ips,count(distinct d.tkid) uv \n-- from data d --(select timestamp,source,devicestype,province,eventid,ssid,ip,tkid from data where substr(timestamp,1,10) = date_sub(now(),11)) d \n-- right join date_dim t on substr(d.timestamp,1,10)=t.date and t.date=date_sub(now(),11) \n-- where substr(d.timestamp,1,10) = date_sub(now(),11)\n-- group by t.y,t.q,t.date,d.source,d.devicestype,d.province","user":"ljj","dateUpdated":"2017-06-15T20:17:25+0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"eventid","index":0,"aggr":"sum"}],"values":[{"name":"timestamp","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"eventid","index":0,"aggr":"sum"},"yAxis":{"name":"timestamp","index":1,"aggr":"sum"}}},"enabled":true,"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1497266616961_1565713705","id":"20170612-192336_850990990","result":{"code":"SUCCESS","type":"TABLE","msg":"eventid\ttimestamp\ttkid\tssId\tproperties\tversion\tregion_code\tip\tsourcetype\tsource\tdevicestype\tcountry\tprovince\tcity\n45c5a3e1-6c51-4fab-9fac-3ad3a8ad1cbb\t2017-06-15T20:10:47+08:00\t15caba9a59a28-08a48d34387a21-62101875-1296000-15caba9a59ba8f\t15caba9a59c795-0ccb86609c906c-62101875-1296000-15caba9a59db4c\t[chrome,58,pc,windows,6.1,,,,900,1440,https://www.twotiger.com/act/act_17_6_2,twotiger.com,www.twotiger.com,/act/act_17_6_2,火热红包，利享6月两只老虎理财官网-安全灵活高收益的互联网金融信息服务平台]\t1.0.1\t22\t183.194.70.206\t其它\t其它\tpc\t中国\t上海\t上海\n557eb3fe-2e04-4841-8b8a-946856b1d365\t2017-06-15T20:15:10+08:00\t15c5dbedb2665d-0a3f6fac65ab95-3e64430f-2073600-15c5dbedb2740d\t15cabadda48cb-0bd5e1c8b7dad5-3e64430f-2073600-15cabadda495bd\t[chrome,50,pc,windows,10,,,,1080,1920,https://www.twotiger.com/project,twotiger.com,www.twotiger.com,/project,我要投资 网贷理财产品 两只老虎理财官网-安全灵活高收益的互联网金融信息服务平台]\t1.0.1\t22\t123.118.157.208\t其它\t其它\tpc\t中国\t北京\t北京\n","comment":"","msgTable":[[{"key":"timestamp","value":"45c5a3e1-6c51-4fab-9fac-3ad3a8ad1cbb"},{"key":"timestamp","value":"2017-06-15T20:10:47+08:00"},{"key":"timestamp","value":"15caba9a59a28-08a48d34387a21-62101875-1296000-15caba9a59ba8f"},{"key":"timestamp","value":"15caba9a59c795-0ccb86609c906c-62101875-1296000-15caba9a59db4c"},{"key":"timestamp","value":"[chrome,58,pc,windows,6.1,,,,900,1440,https://www.twotiger.com/act/act_17_6_2,twotiger.com,www.twotiger.com,/act/act_17_6_2,火热红包，利享6月两只老虎理财官网-安全灵活高收益的互联网金融信息服务平台]"},{"key":"timestamp","value":"1.0.1"},{"key":"timestamp","value":"22"},{"key":"timestamp","value":"183.194.70.206"},{"key":"timestamp","value":"其它"},{"key":"timestamp","value":"其它"},{"key":"timestamp","value":"pc"},{"key":"timestamp","value":"中国"},{"key":"timestamp","value":"上海"},{"key":"timestamp","value":"上海"}],[{"key":"tkid","value":"557eb3fe-2e04-4841-8b8a-946856b1d365"},{"key":"tkid","value":"2017-06-15T20:15:10+08:00"},{"key":"tkid","value":"15c5dbedb2665d-0a3f6fac65ab95-3e64430f-2073600-15c5dbedb2740d"},{"key":"tkid","value":"15cabadda48cb-0bd5e1c8b7dad5-3e64430f-2073600-15cabadda495bd"},{"key":"tkid","value":"[chrome,50,pc,windows,10,,,,1080,1920,https://www.twotiger.com/project,twotiger.com,www.twotiger.com,/project,我要投资 网贷理财产品 两只老虎理财官网-安全灵活高收益的互联网金融信息服务平台]"},{"key":"tkid","value":"1.0.1"},{"key":"tkid","value":"22"},{"key":"tkid","value":"123.118.157.208"},{"key":"tkid","value":"其它"},{"key":"tkid","value":"其它"},{"key":"tkid","value":"pc"},{"key":"tkid","value":"中国"},{"key":"tkid","value":"北京"},{"key":"tkid","value":"北京"}]],"columnNames":[{"name":"eventid","index":0,"aggr":"sum"},{"name":"timestamp","index":1,"aggr":"sum"},{"name":"tkid","index":2,"aggr":"sum"},{"name":"ssId","index":3,"aggr":"sum"},{"name":"properties","index":4,"aggr":"sum"},{"name":"version","index":5,"aggr":"sum"},{"name":"region_code","index":6,"aggr":"sum"},{"name":"ip","index":7,"aggr":"sum"},{"name":"sourcetype","index":8,"aggr":"sum"},{"name":"source","index":9,"aggr":"sum"},{"name":"devicestype","index":10,"aggr":"sum"},{"name":"country","index":11,"aggr":"sum"},{"name":"province","index":12,"aggr":"sum"},{"name":"city","index":13,"aggr":"sum"}],"rows":[["45c5a3e1-6c51-4fab-9fac-3ad3a8ad1cbb","2017-06-15T20:10:47+08:00","15caba9a59a28-08a48d34387a21-62101875-1296000-15caba9a59ba8f","15caba9a59c795-0ccb86609c906c-62101875-1296000-15caba9a59db4c","[chrome,58,pc,windows,6.1,,,,900,1440,https://www.twotiger.com/act/act_17_6_2,twotiger.com,www.twotiger.com,/act/act_17_6_2,火热红包，利享6月两只老虎理财官网-安全灵活高收益的互联网金融信息服务平台]","1.0.1","22","183.194.70.206","其它","其它","pc","中国","上海","上海"],["557eb3fe-2e04-4841-8b8a-946856b1d365","2017-06-15T20:15:10+08:00","15c5dbedb2665d-0a3f6fac65ab95-3e64430f-2073600-15c5dbedb2740d","15cabadda48cb-0bd5e1c8b7dad5-3e64430f-2073600-15cabadda495bd","[chrome,50,pc,windows,10,,,,1080,1920,https://www.twotiger.com/project,twotiger.com,www.twotiger.com,/project,我要投资 网贷理财产品 两只老虎理财官网-安全灵活高收益的互联网金融信息服务平台]","1.0.1","22","123.118.157.208","其它","其它","pc","中国","北京","北京"]]},"dateCreated":"2017-06-12T19:23:36+0800","dateStarted":"2017-06-15T20:17:25+0800","dateFinished":"2017-06-15T20:17:25+0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:196"},{"text":"    loadTim\nval opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"sourceQuerykey\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(\"\"\"\nselect distinct source,type,addr,match\nfrom source_dim\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Overwrite).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show","user":"ljj","dateUpdated":"2017-06-15T16:17:51+0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":false,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496919754705_-1413129097","id":"20170608-190234_1817928712","result":{"code":"SUCCESS","type":"TEXT","msg":"opt: scala.collection.immutable.Map[String,String] = Map(host -> dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717, database -> lzlh, collection -> sourceQuerykey, credentials -> root,admin,mongo2tiger)\nda1: org.apache.spark.sql.DataFrame = [source: string, type: string, addr: string, match: string]\n"},"dateCreated":"2017-06-08T19:02:34+0800","dateStarted":"2017-06-12T20:55:28+0800","dateFinished":"2017-06-12T20:55:29+0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:197"},{"text":"val opt=Map(Host ->\"dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717\", Database -> \"lzlh\",Collection -> \"provinceQuerykey\",\"credentials\"-> \"root,admin,mongo2tiger\")\n    val da1=sqlContext.sql(\"\"\"\nselect distinct province\nfrom area_dim\n\"\"\")\n    da1.write.format(\"com.stratio.datasource.mongodb\").mode(SaveMode.Overwrite).options(opt).save()\n//    val res1=sqlContext.read.format(\"com.stratio.datasource.mongodb\").options(opt).load\n//    res1.show","user":"ljj","dateUpdated":"2017-06-15T16:17:51+0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":false,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1496994223991_859855587","id":"20170609-154343_456129286","result":{"code":"SUCCESS","type":"TEXT","msg":"opt: scala.collection.immutable.Map[String,String] = Map(host -> dds-2ze629d32df5dd941.mongodb.rds.aliyuncs.com:3717, database -> lzlh, collection -> provinceQuerykey, credentials -> root,admin,mongo2tiger)\nda1: org.apache.spark.sql.DataFrame = [province: string]\n"},"dateCreated":"2017-06-09T15:43:43+0800","dateStarted":"2017-06-12T20:55:31+0800","dateFinished":"2017-06-12T20:55:32+0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:198"},{"user":"ljj","dateUpdated":"2017-06-15T16:17:51+0800","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1497001385397_-637909308","id":"20170609-174305_482345059","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2017-06-09T17:43:05+0800","dateStarted":"2017-06-15T16:18:12+0800","dateFinished":"2017-06-15T16:19:08+0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:199"}],"name":"pv job","id":"2CHY3G73J","angularObjects":{"2C2S28DWV:shared_process":[],"2C2ME5Z9T:shared_process":[],"2C5726WWP:shared_process":[],"2C4821YPW:shared_process":[],"2C23S4GTE:shared_process":[],"2C4ACB2H6:shared_process":[],"2C3DW3674:shared_process":[],"2C1TKRBKH:shared_process":[],"2CE818RJ8:shared_process":[],"2C2QRKQWK:shared_process":[],"2C37JBBVP:shared_process":[],"2C2JAH2VM:shared_process":[],"2C293BZQE:shared_process":[],"2C59H7DE9:shared_process":[],"2C3HU9VV7:shared_process":[],"2C3H4C7KJ:shared_process":[],"2C28XTSUU:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}
